{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281d51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e37fa5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langgraph.graph import MessagesState,StateGraph,START,END\n",
    "from IPython.display import Image,display\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "search_tool = TavilySearchResults(description = \"Use this tool for answering current events, news or factual questions.\")\n",
    "\n",
    "tools = [search_tool]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_node = ToolNode(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e828590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: MessagesState):\n",
    "    return{\n",
    "        \"messages\":[llm_with_tools.invoke(state[\"messages\"])]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc9d5561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",tool_node)\n",
    "builder.add_edge(START,\"llm\")\n",
    "builder.add_conditional_edges(\"llm\",tools_condition)\n",
    "builder.add_edge(\"tools\",\"llm\")\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd1e2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\n",
    "        \"messages\":[HumanMessage(content=\"Latest AI news\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e2fdb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Latest AI news\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_mRVsIIo4eLpMXvAss12XtU02)\n",
      " Call ID: call_mRVsIIo4eLpMXvAss12XtU02\n",
      "  Args:\n",
      "    query: latest AI news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"AI News | Latest News | Insights Powering AI-Driven Business Growth\", \"url\": \"https://www.artificialintelligence-news.com/\", \"content\": \"AI News is part of the TechForge Publications series\\n\\nTechForge\\n\\nMagnifying glass and digital brain as separating logic from inference improves AI agent scalability by decoupling core workflows from execution strategies.\\n\\nFeatures\\n\\n# How separating logic and search boosts AI agent scalability\\n\\nFebruary 6, 2026\\n\\nIntuit, Uber, and State Farm trial AI agents inside enterprise workflows\\n\\nAI in Action\\n\\nFebruary 6, 2026\\n\\n# Intuit, Uber, and State Farm trial AI agents inside enterprise workflows\\n\\nArtificial Intelligence\\n\\nFebruary 6, 2026\\n\\n# SuperCool review: Evaluating the reality of autonomous creation\\n\\nAI and Us\\n\\nFebruary 5, 2026\\n\\n# AI Expo 2026 Day 2: Moving experimental pilots to AI production [...] # Gartner Data & Analytics Summit 2026\\n\\n# Gartner Data & Analytics Summit unveils expanded AI agenda for 2026\\n\\n# Build Trust and Value: Design an Effective AI Governance Model\\n\\n# How to Calculate Business Value and Cost for Generative AI Use Cases\\n\\n#### Applications\\n\\n### Thailand becomes one of the first in Asia to get the Sora app\\n\\nEntertainment & Media\\n\\nOctober 30, 2025\\n\\n### Malaysia launches Ryt Bank, its first AI-powered bank\\n\\nFinance AI\\n\\nAugust 26, 2025\\n\\n### Google’s Veo 3 AI video creation tools are now widely available\\n\\nAI in Action\\n\\nJuly 29, 2025\\n\\n#### Computer Vision\\n\\n### US and Japan announce sweeping AI and tech collaboration\\n\\nArtificial Intelligence\\n\\nApril 11, 2024\\n\\n### UK and Canada sign AI compute agreement\\n\\nArtificial Intelligence\\n\\nJanuary 31, 2024 [...] Artificial Intelligence\\n\\nJanuary 31, 2024\\n\\n### Quantum AI represents a ‘transformative advancement’\\n\\nAI Hardware & Chips\\n\\nNovember 14, 2023\\n\\n#### Machine Learning\\n\\n### How AI is changing the way we travel\\n\\nArtificial Intelligence\\n\\nOctober 7, 2025\\n\\n### Spot AI introduces the world’s first universal AI agent builder for security cameras\\n\\nArtificial Intelligence\\n\\nApril 10, 2025\\n\\n### Tony Blair Institute AI copyright report sparks backlash\\n\\nArtificial Intelligence\\n\\nApril 2, 2025\\n\\n#### Enterprise\\n\\n### How separating logic and search boosts AI agent scalability\\n\\nFeatures\\n\\nFebruary 6, 2026\\n\\n### AI Expo 2026 Day 2: Moving experimental pilots to AI production\\n\\nAI and Us\\n\\nFebruary 5, 2026\\n\\n### AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise\\n\\nTechEx Events\", \"score\": 0.84918517}, {\"title\": \"AI News & Artificial Intelligence\", \"url\": \"https://techcrunch.com/category/artificial-intelligence/\", \"content\": \"This photograph taken in Mulhouse, eastern France on October 19, 2023, shows figurines next to the ChatGPT logo. (Photo by SEBASTIEN BOZON/AFP via Getty Images)\\n\\n### The backlash over OpenAI’s decision to retire GPT-4o shows how dangerous AI companions can be\\n\\n### Sapiom raises $15M to help AI agents buy their own tech tools\\n\\nlarge Reddit logo overlaying background of smaller logo silhouettes\\n\\n### Reddit looks to AI search as its next big opportunity\\n\\nAWS signage\\n\\n### AWS revenue continues to soar as cloud demand remains high\\n\\nGoogle CEO Sundar Pichai\\n\\n### Amazon and Google are winning the AI capex race — but what’s the prize?\\n\\n### OpenAI launches new agentic coding model only minutes after Anthropic drops its own\\n\\nElon Musk speaks on a podcast [...] ### Tinder looks to AI to help fight ‘swipe fatigue’ and dating app burnout\\n\\nRoblox 4D\\n\\n### Roblox’s 4D creation feature is now available in open beta\\n\\nElevenLabs logo/splash screen\\n\\n### ElevenLabs raises $500M from Sequoia at an $11 billion valuation\\n\\nAlexa+ logo/splash screen\\n\\n### Alexa+, Amazon’s AI assistant, is now available to everyone in the US\\n\\nFibr AI founders Pritam Roy and Ankur Goyal\\n\\n### Accel doubles down on Fibr AI as agents turn static websites into one-to-one experiences\\n\\nPositron chips\\n\\n### Exclusive: Positron raises $230M Series B to take on Nvidia’s AI chips\\n\\nEvent Logo [...] Elon Musk speaks on a podcast\\n\\n### Elon Musk is getting serious about orbital data centers\\n\\nSam Altman, chief executive officer of OpenAI\\n\\n### OpenAI launches a way for enterprises to build and manage AI agents\\n\\nAnthropic Claude logo\\n\\n### Anthropic releases Opus 4.6 with new ‘agent teams’\\n\\nThe Meta Platforms Inc. pavilion ahead of the World Economic Forum (WEF) in Davos, Switzerland, on Jan. 19, 2025.\\n\\n### Meta tests a stand-alone app for its AI-generated ‘Vibes’ videos\\n\\nA man wearing a large black t-shirt stands in a sunlit office.\\n\\n### Fundamental raises $255M Series A with a new take on big data analysis\\n\\n### ElevenLabs CEO: Voice is the next interface for AI\\n\\nSam Altman\\n\\n### Sam Altman got exceptionally testy over Claude Super Bowl ads\", \"score\": 0.78749067}, {\"title\": \"AI (artificial intelligence)\", \"url\": \"https://www.theguardian.com/technology/artificialintelligenceai\", \"content\": \"## 3 February 2026\\n\\n ### Women in tech and finance at higher risk from AI job losses, report says\\n ### Nils Pratley on finance Elon Musk is taking SpaceX’s minority shareholders for a ride\\n\\n  Nils Pratley\\n ### From ‘nerdy’ Gemini to ‘edgy’ Grok: how developers are shaping AI behaviours\\n ### UK privacy watchdog opens inquiry into X over Grok AI sexual deepfakes\\n\\n ### Anthropic’s launch of AI legal tool hits shares in European data companies\\n ### ‘Deepfakes spreading and more AI companions’: seven takeaways from the latest artificial intelligence safety report\\n\\n## 2 February 2026\\n\\n ### Barnsley rebranded UK’s first ‘tech town’ as US giants join AI push [...] Apparent collapse of Nvidia–OpenAI tie-up raises questions about circular funding and who will bear the cost of AI’s expansion\\n\\n## 4 February 2026\\n\\n ### Mandelson’s links with US tech firm Palantir must be fully exposed, campaigners warn\\n\\n  Government faces call for transparency on former peer’s involvement amid fears he may have leaked more sensitive information\\n ### Business live Software sell-off over AI fears hits global stock markets, but FTSE 100 finishes at closing high on £8bn insurance takeover – as it happened\\n\\n  Rolling coverage of the latest economic and financial news\\n ### Pinterest sacks two engineers for creating software to identify fired workers\\n\\n  Digital pinboard business cutting 15% of workforce as it invests heavily in AI\\n\\n## 3 February 2026 [...] Skip to navigation\\n\\nPrint subscriptions\\n\\nSign in\\n\\n## AI (artificial intelligence)\\n\\n## 6 February 2026\\n\\n ### Trump’s family is embroiled in a $500m UAE scandal. We’ve hardly noticed\\n\\n  Mohamad Bazzi\\n ### Deepfake fraud taking place on an industrial scale, study finds\\n\\n## 5 February 2026\\n\\n ### Brief letters Let’s reach out to American English\\n\\n  Brief letters: Contact sport | Showering in the dark | Clawdbot caper | Dubious duvets | Language for leaseholders\\n ### ‘In the end, you feel blank’: India’s female workers watching hours of abusive content to train AI\\n\\n  Women in rural communities describe trauma of moderating violent and pornographic content for global tech companies\\n ### What does the disappearance of a $100bn deal mean for the AI economy?\", \"score\": 0.735737}, {\"title\": \"Artificial intelligence | Massachusetts Institute of Technology\", \"url\": \"https://news.mit.edu/topic/artificial-intelligence2\", \"content\": \"February 3, 2026\\n\\nRead full story →\\n\\nJacob Payne and Ayah Mahmoud sit at a table, atop of which sits a bright red Kitchen Cosmo machine sits\\n\\n### Counter intelligence\\n\\nArchitecture students bring new forms of human-machine interaction into the kitchen.\\n\\nFebruary 3, 2026\\n\\nRead full story →\\n\\nA roughly 1-inch-wide square wafer sits atop a woman's hand\\n\\n### SMART launches new Wearable Imaging for Transforming Elderly Care research group\\n\\nWITEC is working to develop the first wearable ultrasound imaging system to monitor chronic conditions in real-time, with the goal of enabling earlier detection and timely intervention.\\n\\nFebruary 3, 2026\\n\\nRead full story →\\n\\nA shiny, futuristic molecule\\n\\n### How generative AI can help scientists synthesize complex materials [...] Torralba’s research focuses on computer vision, machine learning, and human visual perception.\\n\\nFebruary 4, 2026\\n\\nRead full story →\\n\\nPortrait photo of Jim Collins in a wet lab\\n\\n### 3 Questions: Using AI to accelerate the discovery and design of therapeutic drugs\\n\\nProfessor James Collins discusses how collaboration has been central to his research into combining computational predictions with new experimental platforms.\\n\\nFebruary 4, 2026\\n\\nRead full story →\\n\\nKatie Spivakovsky stands before outdoor columns at MIT\\n\\n### Katie Spivakovsky wins 2026 Churchill Scholarship\\n\\nThe MIT senior will pursue a master’s degree at Cambridge University in the U.K. this fall.\\n\\nFebruary 3, 2026\\n\\nRead full story → [...] “MechStyle” allows users to personalize 3D models, while ensuring they’re physically viable after fabrication, producing unique personal items and assistive technology.\\n\\nJanuary 14, 2026\\n\\nRead full story →\\n\\nPriya Donti\\n\\n### 3 Questions: How AI could optimize the power grid\\n\\nWhile the growing energy demands of AI are worrying, some techniques can also help make power grids cleaner and more efficient.\\n\\nJanuary 9, 2026\\n\\nRead full story →\\n\\nA United States map with a brightly colored overlay highlighting temperature differences across various states and regions.\\n\\n### Decoding the Arctic to predict winter weather\\n\\nWith the help of AI, MIT Research Scientist Judah Cohen is reshaping subseasonal forecasting, with the goal of extending the lead time for predicting impactful weather.\", \"score\": 0.683948}, {\"title\": \"The trends that will shape AI and tech in 2026 - IBM\", \"url\": \"https://www.ibm.com/think/news/ai-tech-trends-predictions-2026\", \"content\": \"After much skepticism around AI’s ROI, AI capabilities will pave new ways to do business in the enterprise. And open-source reasoning models and agents will keep pushing boundaries to conquer enterprise AI.\\n\\nAt the same time, trust and security will become key priorities as many enterprises sharpen their focus on AI sovereignty.\\n\\nThat’s just the opening act for what’s to come in enterprise tech in the days ahead. Read on for 18 expert predictions to watch out for in 2026.\\n\\nIndustry newsletter\\n\\n### The latest AI trends, brought to you by experts\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement.\\n\\n### Thank you! You are subscribed.\", \"score\": 0.6821721}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some of the latest developments in AI:\n",
      "\n",
      "1. **OpenAI’s GPT-4o Retirement Backlash**: OpenAI's recent move to retire its GPT-4o model has faced criticism, highlighting concerns about the implications of AI companions. [Read more here.](https://techcrunch.com/category/artificial-intelligence/)\n",
      "\n",
      "2. **Sapiom Secures Funding**: AI company Sapiom has raised $15 million to help AI agents procure their own technological tools. [Details here.](https://techcrunch.com/category/artificial-intelligence/)\n",
      "\n",
      "3. **AI in Job Risks**: A report indicates that women in tech and finance are at a higher risk of job losses due to AI advancements. [More information available.](https://www.theguardian.com/technology/artificialintelligenceai)\n",
      "\n",
      "4. **AI Collaboration Between Nations**: The US and Japan have announced a significant partnership focused on AI technologies, aiming for collaborative advancements. [Learn more.](https://www.artificialintelligence-news.com/)\n",
      "\n",
      "5. **MIT's AI Research**: Researchers at MIT have launched new initiatives focusing on how generative AI can aid in synthesizing complex materials and accelerating drug discovery. [Explore the research.](https://news.mit.edu/topic/artificial-intelligence2)\n",
      "\n",
      "6. **AI Trends for 2026**: Experts predict that AI capabilities will reshape enterprise business operations, with trust and security becoming critical as companies focus on AI sovereignty. [Read the predictions.](https://www.ibm.com/think/news/ai-tech-trends-predictions-2026)\n",
      "\n",
      "7. **AI Applications**: Countries like Malaysia have introduced AI-powered banking services, emphasizing the growing role of AI in finance and everyday applications. [Get the details.](https://www.artificialintelligence-news.com/)\n",
      "\n",
      "For more in-depth articles and the latest updates, visit AI news platforms like [TechCrunch](https://techcrunch.com/category/artificial-intelligence/) and other dedicated AI news websites.\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd9daa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-6.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (4.12.1)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.128.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==2.0.3 (from gradio)\n",
      "  Using cached gradio_client-2.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (3.11.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (25.0)\n",
      "Collecting pandas<4.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<13.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (2.12.5)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.22-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pytz>=2017.2 (from gradio)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7 (from gradio)\n",
      "  Using cached safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (0.52.1)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from gradio) (0.40.0)\n",
      "Collecting fsspec (from gradio-client==2.0.3->gradio)\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.4.2)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.2)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from pandas<4.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from pandas<4.0,>=1.0->gradio) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.3.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<4.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-6.5.1-py3-none-any.whl (24.2 MB)\n",
      "   ---------------------------------------- 0.0/24.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.1/24.2 MB 15.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.0/24.2 MB 15.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.2/24.2 MB 14.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.3/24.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.2/24.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.4/24.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.2 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.2/24.2 MB 14.0 MB/s  0:00:01\n",
      "Using cached gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading fastapi-0.128.3-py3-none-any.whl (105 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 553.3/553.3 kB 6.0 MB/s  0:00:00\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.1/9.7 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.3/9.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.7 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 14.1 MB/s  0:00:00\n",
      "Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 3.1/7.0 MB 15.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.3/7.0 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 13.8 MB/s  0:00:00\n",
      "Using cached safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl (369 kB)\n",
      "Downloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "Downloading python_multipart-0.0.22-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading rich-14.3.2-py3-none-any.whl (309 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: pytz, pydub, brotli, tomlkit, shellingham, semantic-version, python-multipart, pillow, mdurl, hf-xet, groovy, fsspec, filelock, ffmpy, audioop-lts, annotated-doc, aiofiles, typer-slim, pandas, markdown-it-py, safehttpx, rich, huggingface-hub, fastapi, typer, gradio-client, gradio\n",
      "\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   ----------------------------------------  0/27 [pytz]\n",
      "   - --------------------------------------  1/27 [pydub]\n",
      "   ---- -----------------------------------  3/27 [tomlkit]\n",
      "   ------- --------------------------------  5/27 [semantic-version]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ---------- -----------------------------  7/27 [pillow]\n",
      "   ----------- ----------------------------  8/27 [mdurl]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ---------------- ----------------------- 11/27 [fsspec]\n",
      "   ------------------- -------------------- 13/27 [ffmpy]\n",
      "   ----------------------- ---------------- 16/27 [aiofiles]\n",
      "   ------------------------- -------------- 17/27 [typer-slim]\n",
      "   ------------------------- -------------- 17/27 [typer-slim]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   -------------------------- ------------- 18/27 [pandas]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   ------------------------------- -------- 21/27 [rich]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   -------------------------------- ------- 22/27 [huggingface-hub]\n",
      "   ---------------------------------- ----- 23/27 [fastapi]\n",
      "   ---------------------------------- ----- 23/27 [fastapi]\n",
      "   ---------------------------------- ----- 23/27 [fastapi]\n",
      "   ---------------------------------- ----- 23/27 [fastapi]\n",
      "   ----------------------------------- ---- 24/27 [typer]\n",
      "   ----------------------------------- ---- 24/27 [typer]\n",
      "   ------------------------------------- -- 25/27 [gradio-client]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   -------------------------------------- - 26/27 [gradio]\n",
      "   ---------------------------------------- 27/27 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 audioop-lts-0.2.2 brotli-1.2.0 fastapi-0.128.3 ffmpy-1.0.0 filelock-3.20.3 fsspec-2026.2.0 gradio-6.5.1 gradio-client-2.0.3 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.4.1 markdown-it-py-4.0.0 mdurl-0.1.2 pandas-3.0.0 pillow-12.1.0 pydub-0.25.1 python-multipart-0.0.22 pytz-2025.2 rich-14.3.2 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.13.3 typer-0.21.1 typer-slim-0.21.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "502e357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def chat_with_agent(user_input, history):\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    # Handle both tuple and dict history formats\n",
    "    for item in history:\n",
    "\n",
    "        # New Gradio format (dict)\n",
    "        if isinstance(item, dict):\n",
    "            if item[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=item[\"content\"]))\n",
    "            else:\n",
    "                messages.append(AIMessage(content=item[\"content\"]))\n",
    "\n",
    "        # Old Gradio format (tuple)\n",
    "        else:\n",
    "            human, ai = item\n",
    "            messages.append(HumanMessage(content=human))\n",
    "            messages.append(AIMessage(content=ai))\n",
    "\n",
    "    # Add latest user message\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "\n",
    "    result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "    final_ai = next(\n",
    "        m.content for m in reversed(result[\"messages\"])\n",
    "        if m.type == \"ai\" and m.content\n",
    "    )\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    history.append({\"role\": \"assistant\", \"content\": final_ai})\n",
    "\n",
    "    return \"\", history\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    gr.Markdown(\"## 🔎 LangGraph Search Agent\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=200)\n",
    "    msg = gr.Textbox(placeholder=\"Ask something...\")\n",
    "\n",
    "    msg.submit(chat_with_agent, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70dc20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m MessagesState(self, /, *args, **kwargs)\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "dict() -> new empty dictionary\n",
      "dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "    (key, value) pairs\n",
      "dict(iterable) -> new dictionary initialized as if via:\n",
      "    d = {}\n",
      "    for k, v in iterable:\n",
      "        d[k] = v\n",
      "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "    in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m MessagesState(TypedDict):\n",
      "    messages: Annotated[list[AnyMessage], add_messages]\n",
      "\u001b[31mFile:\u001b[39m           c:\\users\\jay.sahu\\langchain-academy\\lc-academy-env\\lib\\site-packages\\langgraph\\graph\\message.py\n",
      "\u001b[31mType:\u001b[39m           _TypedDictMeta\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "MessagesState??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d7b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
